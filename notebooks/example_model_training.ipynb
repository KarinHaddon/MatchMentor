{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame</th>\n",
       "      <th>Possession</th>\n",
       "      <th>Set piece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frame  Possession  Set piece\n",
       "0    410           1          0\n",
       "1    420           1          0\n",
       "2    430           1          0\n",
       "3    440           1          0\n",
       "4    450           1          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Initialize target outputs: read our labels from a file and convert them to a 2-d tensor.\"\"\"\n",
    "\n",
    "labels_path = Path(r\"C:\\Users\\jai\\veo_nu\\data\\labels\\Initial_combined_labels.csv\")  # path to labels file\n",
    "labels_df = pd.read_csv(labels_path)  # read the labels file into a pandas dataframe table\n",
    "display(labels_df.head())  # display the first few rows of the labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([680, 2])\n"
     ]
    }
   ],
   "source": [
    "Y = labels_df[[\"Possession\", \"Set piece\"]].values  # extract the \"Possession\" and \"Set piece\" values\n",
    "Y = torch.from_numpy(Y).float()  # convert the extracted values to a 2-d tensor\n",
    "print(Y.shape)  # print the shape of the initialized target outputs\n",
    "N = Y.shape[0]  # number of samples (total number of combined labeled frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([680, 3, 360, 640])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialize inputs: convert the frame images to a list of 3-d tensors (width X height X rgb).\"\"\"\n",
    "\n",
    "frames_path = Path(r\"C:\\Users\\jai\\veo_nu\\data\\initial_combined_frames\")  # path to image directory\n",
    "n_channels, height, width = 3, 360, 640  # initialize the dimensions of the frames\n",
    "X = torch.empty((N, n_channels, height, width))  # initialize a tensor that will store all frames\n",
    "print(X.shape)  # print shape of initialized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(frames_path.glob(\"*.png\")):  # find each image file in `frames_path` directory\n",
    "    with Image.open(file).convert(\"RGB\") as img:  # open the image file and convert to RGB\n",
    "        to_tensor = transforms.ToTensor()  # initialize a ToTensor conversion object\n",
    "        img_tensor = to_tensor(img).float()  # use the ToTensor object to convert the image to a tensor\n",
    "        X[i, :] = img_tensor  # add the tensor of the current frame to our list of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create Dataset and DataLoader.\"\"\"\n",
    "\n",
    "dataset = CustomDataset(images, labels, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configure model\"\"\"\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Modify the classifier to output 2 probabilities\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier.in_features, 2),\n",
    "    nn.Sigmoid()  # Use sigmoid for binary multiclass (multi-label) classification\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train model\"\"\"\n",
    "\n",
    "num_epochs = 10  # Define the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

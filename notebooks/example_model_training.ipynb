{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports.\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Specify which device (CPU or GPU) to use\"\"\"\n",
    "\n",
    "if torch.cuda.is_available():  # if we have a GPU and its available to pytorch, use it\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU device: {torch.cuda.get_device_name(device)}\\n\")\n",
    "else:  # else, use cpu\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize target outputs: read our labels from a file and convert them to a 2-d tensor.\"\"\"\n",
    "\n",
    "labels_path = Path(r\"C:\\Users\\jai\\veo_nu\\data\\labels\\Initial_combined_labels.csv\")  # path to labels file\n",
    "labels_df = pd.read_csv(labels_path)  # read the labels file into a pandas dataframe table\n",
    "display(labels_df.head())  # display the first few rows of the labels dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = labels_df[[\"Possession\", \"Set piece\"]].values  # extract the \"Possession\" and \"Set piece\" values\n",
    "Y = torch.from_numpy(Y).float().to(device)  # convert the extracted values to a 2-d tensor\n",
    "print(Y.shape)  # print the shape of the initialized target outputs\n",
    "N, n_classes = Y.shape[0], Y.shape[1]  # number of samples, number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize inputs: convert the frame images to a list of 3-d tensors (width X height X rgb).\"\"\"\n",
    "\n",
    "frames_path = Path(r\"C:\\Users\\jai\\veo_nu\\data\\initial_combined_frames\")  # path to image directory\n",
    "n_channels, height, width = 3, 224, 224  # initialize the dimensions of the frames\n",
    "X = torch.empty((N, n_channels, height, width))  # initialize a tensor that will store all frames\n",
    "print(X.shape)  # print shape of initialized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fill in `X` frame-by-frame.\"\"\"\n",
    "\n",
    "for i, file in enumerate(frames_path.glob(\"*.png\")):  # find each image file in `frames_path` directory\n",
    "    with Image.open(file).convert(\"RGB\") as img:  # open the image file and convert to RGB\n",
    "        to_tensor = transforms.ToTensor()  # initialize a ToTensor conversion object\n",
    "        resize = transforms.Resize((height, width))  # initialize a Resize object\n",
    "        img_tensor = to_tensor(img).float()  # use the ToTensor object to convert the image to a tensor (will be normalized pixel values between 0-1)\n",
    "        img_tensor = resize(img_tensor)  # use the Resize object to resize the tensor to the specified dimensions\n",
    "        X[i, :] = img_tensor  # add the tensor of the current frame to our list of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create Datasets and DataLoader.\"\"\"\n",
    "\n",
    "# Create training, testing, and validation datasets.\n",
    "dataset = TensorDataset(X, Y)\n",
    "train_data, val_data = random_split(dataset, [0.90, 0.10])\n",
    "# View training and validation data subsets.\n",
    "print(train_data[:][0].shape, train_data[:][1].shape, val_data[:][0].shape, val_data[:][1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create function to perform gradient centralization during training.\"\"\"\n",
    "\n",
    "def apply_gradient_centralization(optimizer):\n",
    "    \"\"\"Applies gradient centralization to the optimizer.\n",
    "    \n",
    "    This function should be called before optimizer.step() in the training loop.\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                # Compute the mean of the gradient\n",
    "                grad_mean = param.grad.data.mean(dim=tuple(range(1, len(param.grad.shape))), keepdim=True)\n",
    "                # Centralize the gradient\n",
    "                param.grad.data -= grad_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create function to train the model.\"\"\"\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,  # model\n",
    "    train_loader: DataLoader,  # batched dataset for training\n",
    "    val_loader: DataLoader,  # batched dataset for validation\n",
    "    optimizer: optim,  # optimizer for performing parameter update step\n",
    "    loss_fn: nn.modules.loss,  # loss function\n",
    "    max_epochs: int = 5,  # max n training epochs\n",
    "    val_check_interval: int = 1,  # check val loss every `val_check_interval` batches\n",
    ") -> tuple[torch.Tensor, np.ndarray, np.ndarray]:  # -> loss, train_losses, val_losses\n",
    "    \"\"\"Trains a model, returns loss.\"\"\"\n",
    "    # <s Create Trackers\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    # <s Go through training and validation loop\n",
    "    for epoch in range(max_epochs):  # epoch is all frames in our \"train\" dataset\n",
    "        for batch_i, (x_train, y_train) in enumerate(train_loader):  # get train batch of frames and labels\n",
    "            # <ss Model training.\n",
    "            model.train()  # set model to training mode (which means it's computing gradients)\n",
    "            optimizer.zero_grad()  # set all gradients to zero for the current step\n",
    "            out = model(x_train)  # forward pass through the model\n",
    "            loss = loss_fn(out, y_train)  # compute loss\n",
    "            loss.backward()  # backward pass back through the model to compute gradients\n",
    "            train_losses.append(loss.item())  # append the current train loss to list of train losses\n",
    "            # /ss>\n",
    "            # <ss Model validation (for early stopping).\n",
    "            if i % val_check_interval == 0:  # every `val_check_interval` batches check val_loss and print\n",
    "                model.eval()  # set model to eval mode\n",
    "                with torch.no_grad():  # ensure gradients aren't computed\n",
    "                    x_val, y_val = next(iter(val_loader))  # get val batch of frames and labels\n",
    "                    val_loss = loss_fn(model(x_val), y_val).item()  # compute val loss\n",
    "                    val_losses.append(val_loss)  # append the current val loss to list of val losses\n",
    "                print(  # print the current epoch, batch, train loss, and val loss\n",
    "                    f\"Epoch {epoch + 1}: Batch {batch_i + 1}:  \"\n",
    "                    f\"Loss = {train_losses[-1]:.3f}, Val Loss = {val_losses[-1]:.3f}\"\n",
    "                )\n",
    "            # /ss>\n",
    "    # /s>\n",
    "    print(\"Finished training:\")\n",
    "    print(f\"Epoch {epoch + 1}:  Batch {batch_i + 1}: Loss = {train_losses[-1]:.3f}, Val Loss = {val_losses[-1]:.3f}\")\n",
    "    return loss, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load in initial pretrained model.\"\"\"\n",
    "\n",
    "# Load in model that was used for AlexNet\n",
    "# Possible pretrained models to try: DenseNet121_Weights, DenseNet169_Weights, ResNet50_Weights, ResNet101_Weights\n",
    "\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configure model (just change last layer in model)\"\"\"\n",
    "\n",
    "dropout_rate = 0.2  # 20% cell removal to help with generalization\n",
    "\n",
    "# Modify the classifier to output 2 probabilities\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(dropout_rate),\n",
    "    nn.Linear(model.classifier.in_features, n_classes),\n",
    "    nn.Sigmoid()  # Use sigmoid for binary multiclass, multilabel classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train model.\"\"\"\n",
    "\n",
    "batch_size = 32  # number of frames in each batch to process when computing loss\n",
    "lr = 0.05  # learning rate: scale factor used in the parameter update step\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "# Set loss function and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02, weight_decay=1e-7, momentum=0.5, nesterov=True)\n",
    "# Train\n",
    "loss, train_losses, val_losses = train(\n",
    "    model, train_loader, val_loader, optimizer, loss_fn, max_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation losses\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_losses, label=\"Train\")\n",
    "ax.plot(val_losses, label=\"Val\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Batch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training and Validation Losses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View val images and see how it performed\n",
    "\n",
    "val_frame = val_data[:][0][0].unsqueeze(0)  # shape of first val image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model(val_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[:][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
